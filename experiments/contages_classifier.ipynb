{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('cognates', 'rb') as f:\n",
    "    cognates = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cognates_sub = cognates[:100]\n",
    "\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "cognates_stemmed = [(stemmer.stem(word), i) for word, i in cognates_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lcs(a, b):\n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    # read the substring out from the matrix\n",
    "    result = \"\"\n",
    "    x, y = len(a), len(b)\n",
    "    while x != 0 and y != 0:\n",
    "        if lengths[x][y] == lengths[x-1][y]:\n",
    "            x -= 1\n",
    "        elif lengths[x][y] == lengths[x][y-1]:\n",
    "            y -= 1\n",
    "        else:\n",
    "            assert a[x-1] == b[y-1]\n",
    "            result = a[x-1] + result\n",
    "            x -= 1\n",
    "            y -= 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for word_1, class_1 in cognates_stemmed:\n",
    "    for word_2, class_2 in cognates_stemmed:\n",
    "        if word_1 == word_2:\n",
    "            continue\n",
    "        y.append(1 if class_1 == class_2 else 0)\n",
    "        X.append([\n",
    "                    levenshtein(word_1, word_2) / max(len(word_1), len(word_2)),\n",
    "                    abs(len(word_1) - len(word_2)),\n",
    "                    len(lcs(word_1, word_2)) / max(len(word_1), len(word_2))\n",
    "                 ]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_svm = clf.predict(X_test)\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier()\n",
    "#clf.fit(X_train, y_train)\n",
    "#y_pred_rf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8928571428571429, 0.6983240223463687, 0.78369905956112851, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = list(map(lambda x: 0 if x < 0.95 else 1, y_pred_svm))\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision_recall_fscore_support(y_test, y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.94615234,  0.05384766])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([y_pred_svm[0], y_pred_rf[0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.5288377 ,  0.20594365,  8.06039389]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
